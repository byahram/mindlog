import os
import pickle
from datetime import datetime
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import gradio as gr
from transformers import AutoTokenizer, AutoModel

def set_korean_font():
    candidates = ["Malgun Gothic", "AppleGothic", "NanumGothic", "Noto Sans KR"]
    available = {f.name for f in fm.fontManager.ttflist}
    for name in candidates:
        if name in available:
            plt.rcParams["font.family"] = name
            plt.rcParams["axes.unicode_minus"] = False
            return name
    return "sans-serif"

set_korean_font()


# =========================
# 0. Config
# =========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

class Config:
    DATA_DIR  = os.path.join(BASE_DIR, "data", "processed")
    MODEL_DIR = os.path.join(BASE_DIR, "models")

    MODEL_NAME = "beomi/KcELECTRA-base-v2022"
    CKPT_NAME  = "best_multitask_model.bin"

    MAX_LEN = 128
    DEVICE  = torch.device("cuda" if torch.cuda.is_available() else "cpu")

os.makedirs(Config.MODEL_DIR, exist_ok=True)
print("[INFO] Device:", Config.DEVICE)


# =========================
# 1. Load label_map
# =========================
label_map_path = os.path.join(Config.DATA_DIR, "label_map.pkl")
if not os.path.exists(label_map_path):
    raise FileNotFoundError(f"label_map.pkl not found: {label_map_path}")

with open(label_map_path, "rb") as f:
    label_map = pickle.load(f)

id2emotion   = label_map["id2emotion"]
id2situation = label_map["id2situation"]

num_emo = len(label_map["emotion2id"])
num_sit = len(label_map["situation2id"])

emo_names = [id2emotion[i] for i in range(num_emo)]
sit_names = [id2situation[i] for i in range(num_sit)]

print("[INFO] num_emo:", num_emo, "num_sit:", num_sit)


# =========================
# 2. Model + tokenizer + ckpt load
# =========================
class SentimentMultiTaskModel(nn.Module):
    def __init__(self, model_name, num_emo_classes, num_sit_classes):
        super().__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        hidden = self.encoder.config.hidden_size
        self.dropout = nn.Dropout(0.1)
        self.emo_classifier = nn.Linear(hidden, num_emo_classes)
        self.sit_classifier = nn.Linear(hidden, num_sit_classes)

    def forward(self, input_ids, attention_mask):
        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls = self.dropout(out.last_hidden_state[:, 0, :])
        return {
            "logits_emotion": self.emo_classifier(cls),
            "logits_situation": self.sit_classifier(cls),
        }

tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)
model = SentimentMultiTaskModel(Config.MODEL_NAME, num_emo, num_sit).to(Config.DEVICE)

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
ckpt_path = os.path.join(Config.MODEL_DIR, Config.CKPT_NAME)
if os.path.exists(ckpt_path):
    state = torch.load(ckpt_path, map_location=Config.DEVICE)
    model.load_state_dict(state)
    model.eval()
    print("[INFO] Loaded ckpt:", ckpt_path)
else:
    print("[WARN] Checkpoint not found. Running with random weights.")


# =========================
# 3. Predict / history / save
# =========================
def predict_probs(text: str):
    """ëª¨ë¸ ì˜ˆì¸¡ í›„ dict í˜•íƒœë¡œ ë°˜í™˜ (Gradio Labelìš©)"""
    text = (text or "").strip()
    enc = tokenizer(text, max_length=Config.MAX_LEN, padding="max_length", truncation=True, return_tensors="pt")
    enc = {k: v.to(Config.DEVICE) for k, v in enc.items()}

    model.eval()
    with torch.inference_mode():
        out = model(input_ids=enc["input_ids"], attention_mask=enc["attention_mask"])

    emo_probs_t = F.softmax(out["logits_emotion"], dim=-1)[0]
    sit_probs_t = F.softmax(out["logits_situation"], dim=-1)[0]

    emo_dict = {emo_names[i]: float(emo_probs_t[i]) for i in range(len(emo_names))}
    sit_dict = {sit_names[i]: float(sit_probs_t[i]) for i in range(len(sit_names))}

    # Best Picking
    emo_id = int(torch.argmax(emo_probs_t).item())
    sit_id = int(torch.argmax(sit_probs_t).item())
    
    return emo_id, emo_probs_t.max().item(), sit_id, sit_probs_t.max().item(), emo_dict, sit_dict

def append_turn(history, user_text, emo_id, emo_conf, sit_id, sit_conf):
    turn = len(history) + 1
    history.append({
        "turn": turn,
        "ts": datetime.now().strftime("%H:%M:%S"), 
        "text": user_text,
        "emotion": id2emotion[emo_id],
        "emo_conf": round(emo_conf, 2),
        "situation": id2situation[sit_id],
        "sit_conf": round(sit_conf, 2),
        "emo_id": emo_id,
        "sit_id": sit_id 
    })
    return history

# def save_history_csv(history, filename_prefix="chat_history"):
#     ts = datetime.now().strftime("%y%m%d_%H%M")
#     filename = f"{filename_prefix}_{ts}.csv"
#     path = os.path.join(Config.MODEL_DIR, filename)

#     df = pd.DataFrame(history).drop(columns=["emotion_probs", "situation_probs"], errors="ignore")
#     df.to_csv(path, index=False, encoding="utf-8-sig")
#     return path

# def format_current_pred(emo_id, emo_conf, sit_id, sit_conf):
#     emo = id2emotion[emo_id]
#     sit = id2situation[sit_id]
#     return (
#         f"### í˜„ì¬ ì˜ˆì¸¡\n"
#         f"- ê°ì •: **{emo}** (conf={emo_conf:.2f})\n"
#         f"- ìƒí™©: **{sit}** (conf={sit_conf:.2f})\n\n"
#         f"**confidence** = ëª¨ë¸ì´ ê³ ë¥¸ 1ë“± ë¼ë²¨ì˜ í™•ë¥ (softmax)."
#     )

# =========================
# 4. Plot Functions (Timeline)
# =========================
def draw_timeline(history):
    if not history:
        return None, None
    
    df = pd.DataFrame(history)
    
    # Emotion Timeline
    fig_emo = plt.figure(figsize=(12, 4))
    # ì  í¬ê¸°ë¥¼ confidenceì— ë¹„ë¡€í•˜ê²Œ (ìµœì†Œ 50, ìµœëŒ€ 300)
    sizes = df["emo_conf"] * 300 
    plt.scatter(df["turn"], df["emo_id"], s=sizes, c=df["emo_id"], cmap="tab10", alpha=0.7)
    plt.yticks(range(len(emo_names)), emo_names)
    plt.xlabel("Turn")
    plt.title("Emotion Flow")
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.tight_layout()

    # Situation Timeline
    fig_sit = plt.figure(figsize=(12, 4))
    sizes_sit = df["sit_conf"] * 300
    plt.scatter(df["turn"], df["sit_id"], s=sizes_sit, c=df["sit_id"], cmap="Set2", alpha=0.7)
    plt.yticks(range(len(sit_names)), sit_names)
    plt.xlabel("Turn")
    plt.title("Situation Flow")
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.tight_layout()
    
    return fig_emo, fig_sit

# =========================
# 5. UI Event Handlers
# =========================
def on_submit(text, history):
    if not text.strip():
        return "", history, None, None, None, pd.DataFrame()

    # 1. Predict
    e_id, e_conf, s_id, s_conf, e_dict, s_dict = predict_probs(text)
    
    # 2. Update History
    new_history = append_turn(history, text, e_id, e_conf, s_id, s_conf)
    
    # 3. Create Charts
    fig_emo, fig_sit = draw_timeline(new_history)
    df = pd.DataFrame(new_history).drop(columns=["emo_id", "sit_id"]) # ë³´ì—¬ì£¼ê¸°ìš© DFì—ì„œëŠ” ID ì œì™¸
    
    # ë°˜í™˜: ì…ë ¥ì°½ì´ˆê¸°í™”, íˆìŠ¤í† ë¦¬ì—…ë°ì´íŠ¸, ê°ì •ë¼ë²¨, ìƒí™©ë¼ë²¨, ê°ì •ì°¨íŠ¸, ìƒí™©ì°¨íŠ¸, ë°ì´í„°í”„ë ˆì„
    return "", new_history, e_dict, s_dict, fig_emo, fig_sit, df

def on_reset():
    return [], None, None, None, None, pd.DataFrame()

# =========================
# 6. Gradio Build (Clean Version)
# =========================
def build_app():
    with gr.Blocks() as demo:
        
        # [Header]
        gr.Markdown(
            """
            # ğŸ‹ Mind Log: Silent Tracker
            ### "ë§í•˜ì§€ ì•Šì•„ë„ ë“œëŸ¬ë‚˜ëŠ” ê°ì •ì˜ íë¦„"
            """
        )
        
        # State (ì „ì—­ ë³€ìˆ˜ ëŒ€ì‹  ì„¸ì…˜ë³„ ì €ì¥ì†Œ)
        state_history = gr.State([])

        # [Tabs] ê¸°ëŠ¥ì„ íƒ­ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê¹”ë”í•˜ê²Œ
        with gr.Tabs():
            
            # --- TAB 1: ê¸°ë¡ ë° ì¦‰ì‹œ ë¶„ì„ (Main) ---
            with gr.TabItem("ğŸ“ ê¸°ë¡í•˜ê¸° (Record)"):
                
                # [ìƒë‹¨] ì…ë ¥ ì˜ì—­ (ì „ì²´ ë„ˆë¹„ ì‚¬ìš©)
                with gr.Row():
                    with gr.Column():
                        input_text = gr.Textbox(
                            label="ì§€ê¸ˆ ì–´ë–¤ ë§ˆìŒì¸ê°€ìš”?", 
                            placeholder="ììœ ë¡­ê²Œ í„¸ì–´ë†“ìœ¼ì„¸ìš” (Enterë¡œ ì…ë ¥)", 
                            lines=5
                        )
                        btn_submit = gr.Button("ê¸°ë¡í•˜ê¸°", variant="primary")
                
                # ë””ìì¸ì  êµ¬ë¶„ì„ ìœ„í•œ ì—¬ë°± ë° í—¤ë”
                gr.Markdown("---") 
                gr.Markdown("### ğŸ” ë¶„ì„ ê²°ê³¼")

                # [í•˜ë‹¨] ë¶„ì„ ê²°ê³¼ ì˜ì—­ (ê°ì •ê³¼ ìƒí™©ì„ ë‚˜ë€íˆ ë°°ì¹˜)
                with gr.Row():
                    with gr.Column(scale=1):
                        out_emo_label = gr.Label(label="ê°ì • (Emotion)", num_top_classes=3)
                    
                    with gr.Column(scale=1):
                        out_sit_label = gr.Label(label="ìƒí™© (Situation)", num_top_classes=3)

            # --- TAB 2: ëŒ€ì‹œë³´ë“œ (Dashboard) ---
            with gr.TabItem("ğŸ“Š ëŒ€ì‹œë³´ë“œ (Dashboard)"):
                gr.Markdown("### ğŸŒŠ ê°ì •ê³¼ ìƒí™©ì˜ íë¦„")
                plot_emo = gr.Plot(label="Emotion Timeline")
                plot_sit = gr.Plot(label="Situation Timeline")
                
            # --- TAB 3: ë°ì´í„° ë¡œê·¸ (Data Log) ---
            with gr.TabItem("ğŸ“‚ ë°ì´í„° (History)"):
                with gr.Row():
                    btn_reset = gr.Button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”", size="sm", variant="stop")
                    # btn_save = gr.Button("ğŸ’¾ CSV ì €ì¥", size="sm") # (ì¶”í›„ êµ¬í˜„)
                history_table = gr.Dataframe(
                    headers=["turn", "ts", "text", "emotion", "emo_conf", "situation", "sit_conf"],
                    datatype=["number", "str", "str", "str", "number", "str", "number"],
                    interactive=False
                )

        # [Event Linking]
        # 1. Submit (Enter or Click)
        # ì¶œë ¥ ìˆœì„œ: [ì…ë ¥ì°½, state, ê°ì •ë¼ë²¨, ìƒí™©ë¼ë²¨, ê°ì •ì°¨íŠ¸, ìƒí™©ì°¨íŠ¸, í…Œì´ë¸”]
        input_text.submit(
            fn=on_submit,
            inputs=[input_text, state_history],
            outputs=[input_text, state_history, out_emo_label, out_sit_label, plot_emo, plot_sit, history_table]
        )
        btn_submit.click(
            fn=on_submit,
            inputs=[input_text, state_history],
            outputs=[input_text, state_history, out_emo_label, out_sit_label, plot_emo, plot_sit, history_table]
        )
        
        # 2. Reset
        btn_reset.click(
            fn=on_reset,
            inputs=[],
            outputs=[state_history, out_emo_label, out_sit_label, plot_emo, plot_sit, history_table]
        )

    return demo

if __name__ == "__main__":
    app = build_app()
    app.launch(server_name="127.0.0.1", server_port=7860)