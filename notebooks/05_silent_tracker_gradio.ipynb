{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwT7HvsW6gah",
        "outputId": "c2cb0562-6884-4906-ca6d-44b285148a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[INFO] Google Drive mounted.\n",
            "[INFO] Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# 0. Install + import + font + drive + Config\n",
        "# =========================================\n",
        "!pip -q install gradio transformers torch pandas matplotlib scikit-learn tqdm\n",
        "\n",
        "import os, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "\n",
        "# 한글 폰트\n",
        "try:\n",
        "    !sudo apt-get install -y fonts-nanum >/dev/null\n",
        "    !sudo fc-cache -fv >/dev/null\n",
        "    !rm -rf ~/.cache/matplotlib\n",
        "    plt.rc(\"font\", family=\"NanumBarunGothic\")\n",
        "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Drive 마운트\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    print(\"[INFO] Google Drive mounted.\")\n",
        "except:\n",
        "    print(\"[INFO] Drive mount skipped.\")\n",
        "\n",
        "class Config:\n",
        "    PROJECT_DIR = \"/content/drive/MyDrive/Projects/MindLog\"\n",
        "    DATA_DIR    = os.path.join(PROJECT_DIR, \"processed\")\n",
        "    MODEL_DIR   = os.path.join(PROJECT_DIR, \"models\")\n",
        "\n",
        "    MODEL_NAME  = \"beomi/KcELECTRA-base-v2022\"\n",
        "    CKPT_NAME   = \"best_multitask_model.bin\"\n",
        "\n",
        "    MAX_LEN     = 128\n",
        "    DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "os.makedirs(Config.MODEL_DIR, exist_ok=True)\n",
        "print(\"[INFO] Device:\", Config.DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzONRoONZOBy",
        "outputId": "07c8a1e9-8ba7-412f-b7e7-0100afdfd03e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] num_emo: 6 num_sit: 12\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# 1. Load label_map (id2emotion / id2situation)\n",
        "# =========================================\n",
        "label_map_path = os.path.join(Config.DATA_DIR, \"label_map.pkl\")\n",
        "with open(label_map_path, \"rb\") as f:\n",
        "    label_map = pickle.load(f)\n",
        "\n",
        "id2emotion   = label_map[\"id2emotion\"]\n",
        "id2situation = label_map[\"id2situation\"]\n",
        "\n",
        "num_emo = len(label_map[\"emotion2id\"])\n",
        "num_sit = len(label_map[\"situation2id\"])\n",
        "\n",
        "emo_names = [id2emotion[i] for i in range(num_emo)]\n",
        "sit_names = [id2situation[i] for i in range(num_sit)]\n",
        "\n",
        "print(\"[INFO] num_emo:\", num_emo, \"num_sit:\", num_sit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0HyF8vGL-tm",
        "outputId": "2224f668-cf27-44a5-db1d-1e1da9edfc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Loaded ckpt: /content/drive/MyDrive/Projects/MindLog/models/best_multitask_model.bin\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# 2. Model + tokenizer + ckpt load\n",
        "# =========================================\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "class SentimentMultiTaskModel(nn.Module):\n",
        "    def __init__(self, model_name, num_emo_classes, num_sit_classes):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        hidden = self.encoder.config.hidden_size\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.emo_classifier = nn.Linear(hidden, num_emo_classes)\n",
        "        self.sit_classifier = nn.Linear(hidden, num_sit_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls = self.dropout(out.last_hidden_state[:, 0, :])\n",
        "        return {\n",
        "            \"logits_emotion\": self.emo_classifier(cls),\n",
        "            \"logits_situation\": self.sit_classifier(cls),\n",
        "        }\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "\n",
        "model = SentimentMultiTaskModel(Config.MODEL_NAME, num_emo, num_sit).to(Config.DEVICE)\n",
        "ckpt_path = os.path.join(Config.MODEL_DIR, Config.CKPT_NAME)\n",
        "\n",
        "state = torch.load(ckpt_path, map_location=Config.DEVICE)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "print(\"[INFO] Loaded ckpt:\", ckpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qFUGse6FMHER"
      },
      "outputs": [],
      "source": [
        "# ========================================================\n",
        "# 3. Predict / History / Plots / Save\n",
        "# ========================================================\n",
        "\n",
        "def predict_probs(text: str):\n",
        "    \"\"\"return: emo_id, emo_conf, sit_id, sit_conf, emo_probs(np), sit_probs(np)\"\"\"\n",
        "    text = (text or \"\").strip()\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        max_length=Config.MAX_LEN,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    enc = {k: v.to(Config.DEVICE) for k, v in enc.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(input_ids=enc[\"input_ids\"], attention_mask=enc[\"attention_mask\"])\n",
        "\n",
        "    emo_probs_t = F.softmax(out[\"logits_emotion\"], dim=-1)[0]\n",
        "    sit_probs_t = F.softmax(out[\"logits_situation\"], dim=-1)[0]\n",
        "\n",
        "    emo_id = int(torch.argmax(emo_probs_t).item())\n",
        "    sit_id = int(torch.argmax(sit_probs_t).item())\n",
        "    emo_conf = float(torch.max(emo_probs_t).item())\n",
        "    sit_conf = float(torch.max(sit_probs_t).item())\n",
        "\n",
        "    return emo_id, emo_conf, sit_id, sit_conf, emo_probs_t.detach().cpu().numpy(), sit_probs_t.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "def append_turn(history, user_text, emo_id, emo_conf, sit_id, sit_conf, emo_probs, sit_probs):\n",
        "    turn = len(history) + 1\n",
        "    history.append({\n",
        "        \"turn\": turn,\n",
        "        \"ts\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"user\": user_text,\n",
        "        \"emotion_id\": emo_id,\n",
        "        \"emotion\": id2emotion[emo_id],\n",
        "        \"emotion_conf\": emo_conf,\n",
        "        \"situation_id\": sit_id,\n",
        "        \"situation\": id2situation[sit_id],\n",
        "        \"situation_conf\": sit_conf,\n",
        "        \"emotion_probs\": emo_probs.tolist(),\n",
        "        \"situation_probs\": sit_probs.tolist(),\n",
        "    })\n",
        "    return history\n",
        "\n",
        "\n",
        "def save_history_csv(history, filename_prefix=\"chat_history\"):\n",
        "    ts = datetime.now().strftime(\"%y%m%d_%H%M\")  # yymmdd_hhmm\n",
        "    filename = f\"{filename_prefix}_{ts}.csv\"\n",
        "    path = os.path.join(Config.MODEL_DIR, filename)\n",
        "    df = pd.DataFrame(history).drop(columns=[\"emotion_probs\", \"situation_probs\"], errors=\"ignore\")\n",
        "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
        "    return path\n",
        "\n",
        "def format_current_pred(emo_id, emo_conf, sit_id, sit_conf):\n",
        "    emo = id2emotion[emo_id]\n",
        "    sit = id2situation[sit_id]\n",
        "    return (\n",
        "        f\"### 현재 예측\\n\"\n",
        "        f\"- 감정: **{emo}**  (conf={emo_conf:.2f})\\n\"\n",
        "        f\"- 상황: **{sit}**  (conf={sit_conf:.2f})\\n\\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ghtQd9auFWw9"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# 4. Figures (Top-3 bar / timelines / confidence)\n",
        "# =========================================\n",
        "\n",
        "# -------------------------\n",
        "# Plot: Top-3 bar charts\n",
        "# -------------------------\n",
        "def fig_topk_bar(probs, names, title, k=3):\n",
        "    probs = np.array(probs)\n",
        "    top_idx = probs.argsort()[::-1][:k][::-1]  # 낮->높\n",
        "    top_names = [names[i] for i in top_idx]\n",
        "    top_vals  = probs[top_idx]\n",
        "\n",
        "    fig = plt.figure(figsize=(6, 3))\n",
        "    plt.barh(top_names, top_vals)\n",
        "    plt.xlim(0, 1.0)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"probability\")\n",
        "    plt.grid(True, axis=\"x\", alpha=0.2)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Plot: emotion timeline\n",
        "# -------------------------\n",
        "def fig_emotion_timeline(history):\n",
        "    if not history:\n",
        "        return None\n",
        "    xs = [h[\"turn\"] for h in history]\n",
        "    ys = [h[\"emotion_id\"] for h in history]\n",
        "    conf = [h[\"emotion_conf\"] for h in history]\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 3.2))\n",
        "    plt.scatter(xs, ys, s=[c * 220 for c in conf])\n",
        "    plt.yticks(range(len(emo_names)), emo_names)\n",
        "    plt.xlabel(\"turn\")\n",
        "    plt.ylabel(\"emotion\")\n",
        "    plt.title(\"Emotion timeline (dot size = confidence)\")\n",
        "    plt.grid(True, axis=\"y\", alpha=0.25)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Plot: situation timeline\n",
        "# -------------------------\n",
        "def fig_situation_timeline(history):\n",
        "    if not history:\n",
        "        return None\n",
        "    xs = [h[\"turn\"] for h in history]\n",
        "    ys = [h[\"situation_id\"] for h in history]\n",
        "    conf = [h[\"situation_conf\"] for h in history]\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 3.2))\n",
        "    plt.scatter(xs, ys, s=[c * 220 for c in conf])\n",
        "    plt.yticks(range(len(sit_names)), sit_names)\n",
        "    plt.xlabel(\"turn\")\n",
        "    plt.ylabel(\"situation\")\n",
        "    plt.title(\"Situation timeline (dot size = confidence)\")\n",
        "    plt.grid(True, axis=\"y\", alpha=0.25)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Plot: confidence over turns\n",
        "# -------------------------\n",
        "def fig_confidence(history):\n",
        "    if not history:\n",
        "        return None\n",
        "    xs = [h[\"turn\"] for h in history]\n",
        "    emo_c = [h[\"emotion_conf\"] for h in history]\n",
        "    sit_c = [h[\"situation_conf\"] for h in history]\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 3))\n",
        "    plt.plot(xs, emo_c, marker=\"o\", label=\"emotion conf\")\n",
        "    plt.plot(xs, sit_c, marker=\"o\", label=\"situation conf\")\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.xlabel(\"turn\")\n",
        "    plt.ylabel(\"confidence\")\n",
        "    plt.title(\"Confidence over turns\")\n",
        "    plt.grid(True, alpha=0.25)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KjijPiwRFmvW"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# 5. Session Summary Card\n",
        "# =========================================\n",
        "def build_summary(history):\n",
        "    if not history:\n",
        "        return \"### 세션 요약\\n(아직 데이터 없음)\"\n",
        "\n",
        "    df = pd.DataFrame(history)\n",
        "\n",
        "    # 최빈 감정/상황\n",
        "    top_emo = df[\"emotion\"].value_counts().index[0]\n",
        "    top_sit = df[\"situation\"].value_counts().index[0]\n",
        "\n",
        "    # \"최고 분노 turn\": 분노 중 confidence 최고, 없으면 None\n",
        "    anger_df = df[df[\"emotion\"] == \"분노\"].copy()\n",
        "    if len(anger_df) > 0:\n",
        "        peak_anger_row = anger_df.sort_values(\"emotion_conf\", ascending=False).iloc[0]\n",
        "        peak_anger = f\"turn {int(peak_anger_row['turn'])} (conf={peak_anger_row['emotion_conf']:.2f})\"\n",
        "    else:\n",
        "        peak_anger = \"없음\"\n",
        "\n",
        "    # 가장 확신 낮은 턴(감정/상황 중 낮은 쪽 기준)\n",
        "    df[\"min_conf\"] = df[[\"emotion_conf\", \"situation_conf\"]].min(axis=1)\n",
        "    low_row = df.sort_values(\"min_conf\", ascending=True).iloc[0]\n",
        "    lowest = f\"turn {int(low_row['turn'])} (min_conf={low_row['min_conf']:.2f})\"\n",
        "\n",
        "    total = len(df)\n",
        "    last_ts = df[\"ts\"].iloc[-1]\n",
        "\n",
        "    return (\n",
        "        f\"### 세션 요약\\n\"\n",
        "        f\"- 총 턴: **{total}**\\n\"\n",
        "        f\"- 최빈 감정: **{top_emo}**\\n\"\n",
        "        f\"- 최빈 상황: **{top_sit}**\\n\"\n",
        "        f\"- 최고 분노 턴: **{peak_anger}**\\n\"\n",
        "        f\"- 가장 애매한 턴: **{lowest}**\\n\"\n",
        "        f\"- 마지막 기록: `{last_ts}`\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "iA7-K6bhFrfd",
        "outputId": "4ed0e2a9-b28b-43a8-8db5-b6265868d378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://027f13e7003e4c942d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://027f13e7003e4c942d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://027f13e7003e4c942d.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =========================================\n",
        "# 6. Gradio Dashboard (Silent Tracker)\n",
        "# =========================================\n",
        "def ui_append(user_text, history):\n",
        "    user_text = (user_text or \"\").strip()\n",
        "    if not user_text:\n",
        "        df = pd.DataFrame(history) if history else pd.DataFrame()\n",
        "        return (\n",
        "            \"\", history,\n",
        "            \"텍스트를 입력해줘.\",\n",
        "            None, None,\n",
        "            None, None, None,\n",
        "            \"### 세션 요약\\n(아직 데이터 없음)\",\n",
        "            df, None\n",
        "        )\n",
        "\n",
        "    emo_id, emo_conf, sit_id, sit_conf, emo_probs, sit_probs = predict_probs(user_text)\n",
        "\n",
        "    # history 업데이트\n",
        "    history = append_turn(history, user_text, emo_id, emo_conf, sit_id, sit_conf, emo_probs, sit_probs)\n",
        "\n",
        "    # 저장\n",
        "    csv_path = save_history_csv(history, filename_prefix=\"chat_history\")\n",
        "\n",
        "    # UI 구성\n",
        "    cur_pred_md = format_current_pred(emo_id, emo_conf, sit_id, sit_conf)\n",
        "    emo_bar = fig_topk_bar(emo_probs, emo_names, \"Top-3 Emotion Prob\", k=3)\n",
        "    sit_bar = fig_topk_bar(sit_probs, sit_names, \"Top-3 Situation Prob\", k=3)\n",
        "\n",
        "    emo_tl  = fig_emotion_timeline(history)\n",
        "    sit_tl  = fig_situation_timeline(history)\n",
        "    conf_tl = fig_confidence(history)\n",
        "\n",
        "    summary = build_summary(history)\n",
        "\n",
        "    df = pd.DataFrame(history).drop(columns=[\"emotion_probs\", \"situation_probs\"], errors=\"ignore\")\n",
        "\n",
        "    return \"\", history, cur_pred_md, emo_bar, sit_bar, emo_tl, sit_tl, conf_tl, summary, df, csv_path\n",
        "\n",
        "def ui_reset():\n",
        "    history = []\n",
        "    df = pd.DataFrame()\n",
        "    return (\n",
        "        \"\", history,\n",
        "        \"세션이 초기화됐어.\",\n",
        "        None, None,\n",
        "        None, None, None,\n",
        "        \"### 세션 요약\\n(아직 데이터 없음)\",\n",
        "        df, None\n",
        "    )\n",
        "\n",
        "with gr.Blocks(title=\"MindLog Silent Tracker\") as demo:\n",
        "    gr.Markdown(\"# MindLog Silent Tracker\\nLLM 없이 **분류 + 기록 + 시각화**만 하는 대시보드\")\n",
        "\n",
        "    state_history = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            user_in = gr.Textbox(\n",
        "                label=\"입력 텍스트\",\n",
        "                placeholder=\"여기에 오늘 감정/상황을 적고 Enter(또는 버튼)를 눌러줘\",\n",
        "                lines=4\n",
        "            )\n",
        "            with gr.Row():\n",
        "                btn_add = gr.Button(\"추가(append)\", variant=\"primary\")\n",
        "                btn_reset = gr.Button(\"세션 초기화\", variant=\"secondary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            cur_pred = gr.Markdown(\"아직 입력 없음.\")\n",
        "            with gr.Row():\n",
        "                emo_bar_plot = gr.Plot(label=\"Top-3 Emotion\")\n",
        "                sit_bar_plot = gr.Plot(label=\"Top-3 Situation\")\n",
        "\n",
        "            emo_timeline_plot = gr.Plot(label=\"Emotion Timeline\")\n",
        "            sit_timeline_plot = gr.Plot(label=\"Situation Timeline\")\n",
        "            conf_plot = gr.Plot(label=\"Confidence\")\n",
        "\n",
        "            summary_md = gr.Markdown(\"### 세션 요약\\n(아직 데이터 없음)\")\n",
        "            hist_table = gr.Dataframe(label=\"History\", interactive=False)\n",
        "            csv_file = gr.File(label=\"CSV 다운로드\")\n",
        "\n",
        "    # 버튼 클릭\n",
        "    btn_add.click(\n",
        "        fn=ui_append,\n",
        "        inputs=[user_in, state_history],\n",
        "        outputs=[user_in, state_history, cur_pred,\n",
        "                 emo_bar_plot, sit_bar_plot,\n",
        "                 emo_timeline_plot, sit_timeline_plot, conf_plot,\n",
        "                 summary_md, hist_table, csv_file]\n",
        "    )\n",
        "\n",
        "    # Enter 제출 (Textbox submit)\n",
        "    user_in.submit(\n",
        "        fn=ui_append,\n",
        "        inputs=[user_in, state_history],\n",
        "        outputs=[user_in, state_history, cur_pred,\n",
        "                 emo_bar_plot, sit_bar_plot,\n",
        "                 emo_timeline_plot, sit_timeline_plot, conf_plot,\n",
        "                 summary_md, hist_table, csv_file]\n",
        "    )\n",
        "\n",
        "    btn_reset.click(\n",
        "        fn=ui_reset,\n",
        "        inputs=[],\n",
        "        outputs=[user_in, state_history, cur_pred,\n",
        "                 emo_bar_plot, sit_bar_plot,\n",
        "                 emo_timeline_plot, sit_timeline_plot, conf_plot,\n",
        "                 summary_md, hist_table, csv_file]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYQrJTqX811d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
